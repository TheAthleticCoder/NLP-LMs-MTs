{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT_Model1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0D22Gdx7EA7",
        "outputId": "87db83d6-5341-41b4-d45f-aa01d35ee20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ted-talks-corpus/train.en', 'r') as f:\n",
        "    english_train = f.readlines()\n",
        "with open('/content/drive/MyDrive/ted-talks-corpus/train.fr', 'r') as f:\n",
        "    french_train = f.readlines()\n",
        "with open('/content/drive/MyDrive/ted-talks-corpus/dev.en', 'r') as f:\n",
        "    english_val = f.readlines()\n",
        "with open('/content/drive/MyDrive/ted-talks-corpus/dev.fr', 'r') as f:\n",
        "    french_val = f.readlines()\n",
        "with open('/content/drive/MyDrive/ted-talks-corpus/test.en', 'r') as f:\n",
        "    english_test = f.readlines()\n",
        "with open('/content/drive/MyDrive/ted-talks-corpus/test.fr', 'r') as f:\n",
        "    french_test = f.readlines()\n",
        "\n",
        "print(english_train[:10])\n",
        "print(french_train[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSl2aC337H-f",
        "outputId": "b2ff4494-d0b3-447e-deee-1b3148e0c499"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"David Gallo: This is Bill Lange. I'm Dave Gallo.\\n\", \"And we're going to tell you some stories from the sea here in video.\\n\", \"We've got some of the most incredible video of Titanic that's ever been seen, and we're not going to show you any of it.\\n\", \"The truth of the matter is that the Titanic -- even though it's breaking all sorts of box office records -- it's not the most exciting story from the sea.\\n\", 'And the problem, I think, is that we take the ocean for granted.\\n', 'When you think about it, the oceans are 75 percent of the planet.\\n', 'Most of the planet is ocean water.\\n', 'The average depth is about two miles.\\n', \"Part of the problem, I think, is we stand at the beach, or we see images like this of the ocean, and you look out at this great big blue expanse, and it's shimmering and it's moving and there's waves and there's surf and there's tides, but you have no idea for what lies in there.\\n\", 'And in the oceans, there are the longest mountain ranges on the planet.\\n']\n",
            "['David Gallo: Voici Bill Lange. Je suis Dave Gallo.\\n', 'Nous allons vous raconter quelques histoires de la mer en vidéo.\\n', \"Nous avons des vidéos du Titanic parmi les plus spectaculaires jamais vues. et nous n'allons pas vous en montrer une image.\\n\", \"La vérité est que le Titanic -- même s'il continue de battre toutes les records de recettes -- n'est pas l'histoire la plus passionnante.\\n\", \"Le problème, je crois, est qu'on tient l'océan pour acquis.\\n\", 'Quand vous y pensez, les océans représentent 75% de la planète.\\n', \"La plus grande partie de la planète est d'eau.\\n\", 'La profondeur moyenne est environ 3,2 km.\\n', \"Une partie du problème, je pense, est qu'en étant sur la plage ou en regardant des images de l'océan, comme celles-ci, on voit cette grande étendue bleue, chatoyante, ça bouge, il y a des vagues, il y a du surf et il y a des marées, mais vous n'avez aucune idée de ce qui s'y cache.\\n\", 'Il y existe les chaînes de montagnes les plus longues de la planète.\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SpTTH_Fe7RBp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0tlS_3b7TrZ",
        "outputId": "48be618e-5de6-4be8-8b26-173bc2d951e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lens_of_data(english_train,french_train,english_val,french_val,english_test,french_test):\n",
        "    print(\"English train:\",len(english_train))\n",
        "    print(\"French train:\",len(french_train))\n",
        "    print(\"English val:\",len(english_val))\n",
        "    print(\"French val:\",len(french_val))\n",
        "    print(\"English test:\",len(english_test))\n",
        "    print(\"French test:\",len(french_test))\n",
        "lens_of_data(english_train,french_train,english_val,french_val,english_test,french_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3OlZI17VbD",
        "outputId": "907c272a-e571-4aa5-e639-396ab895dab5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English train: 30000\n",
            "French train: 30000\n",
            "English val: 887\n",
            "French val: 887\n",
            "English test: 1305\n",
            "French test: 1305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#view 5 examples against each other\n",
        "def view_examples(eng_train,fr_train,eng_test,fr_test,eng_dev,fr_dev):\n",
        "    for i in range(3):\n",
        "        print(\"English Train: {} \\n French Train: {} \\n\".format(eng_train[i].strip(), fr_train[i].strip()))\n",
        "        print(\"English Test: {} \\n French Test: {} \\n\".format(eng_test[i].strip(), fr_test[i].strip()))\n",
        "        print(\"English Validation: {} \\n French Validation: {} \\n\".format(eng_dev[i].strip(), fr_dev[i].strip()))\n",
        "view_examples(english_train,french_train,english_test,french_test,english_val,french_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LbO1UV7WtR",
        "outputId": "1201eed1-e744-4876-b87b-accaf50a0881"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Train: David Gallo: This is Bill Lange. I'm Dave Gallo. \n",
            " French Train: David Gallo: Voici Bill Lange. Je suis Dave Gallo. \n",
            "\n",
            "English Test: When I was in my 20s, I saw my very first psychotherapy client. \n",
            " French Test: Quand j'avais la vingtaine, j'ai vu mes tout premiers clients comme psychothérapeute. \n",
            "\n",
            "English Validation: You know, one of the intense pleasures of travel and one of the delights of ethnographic research is the opportunity to live amongst those who have not forgotten the old ways, who still feel their past in the wind, touch it in stones polished by rain, taste it in the bitter leaves of plants. \n",
            " French Validation: Vous savez, un des plaisirs intenses du voyage et un des délices de la recherche ethnographique est la possibilité de vivre parmi ceux qui n'ont pas oublié les anciennes coutumes, qui ressentent encore leur passé souffler dans le vent, qui le touchent dans les pierres polies par la pluie, le dégustent dans les feuilles amères des plantes. \n",
            "\n",
            "English Train: And we're going to tell you some stories from the sea here in video. \n",
            " French Train: Nous allons vous raconter quelques histoires de la mer en vidéo. \n",
            "\n",
            "English Test: I was a Ph.D. student in clinical psychology at Berkeley. \n",
            " French Test: J'étais étudiante en thèse en psychologie clinique à Berkeley. \n",
            "\n",
            "English Validation: Just to know that Jaguar shamans still journey beyond the Milky Way, or the myths of the Inuit elders still resonate with meaning, or that in the Himalaya, the Buddhists still pursue the breath of the Dharma, is to really remember the central revelation of anthropology, and that is the idea that the world in which we live does not exist in some absolute sense, but is just one model of reality, the consequence of one particular set of adaptive choices that our lineage made, albeit successfully, many generations ago. \n",
            " French Validation: Le fait de savoir que les Jaguar shaman voyagent toujours au-delà de la voie lactée, ou que les mythes des anciens Inuit résonnent encore de sens, ou bien que dans l'Himalaya, les Bouddhistes continuent à rechercher le souffle du Dharma, c'est se rappeler de la révélation essentielle de l'anthropologie, et cela veut dire que le monde dans lequel nous vivons n'existe pas dans un sens absolu, mais est uniquement un exemple de réalité, la conséquence d'un ensemble spécifique de choix adaptés établis par notre lignée avec succès, il y a plusieurs générations. \n",
            "\n",
            "English Train: We've got some of the most incredible video of Titanic that's ever been seen, and we're not going to show you any of it. \n",
            " French Train: Nous avons des vidéos du Titanic parmi les plus spectaculaires jamais vues. et nous n'allons pas vous en montrer une image. \n",
            "\n",
            "English Test: She was a 26-year-old woman named Alex. \n",
            " French Test: Elle, c'était une femme de 26 ans appelée Alex. \n",
            "\n",
            "English Validation: And of course, we all share the same adaptive imperatives. \n",
            " French Validation: Bien sûr, nous partageons tous les mêmes impératifs d'adaptation. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_train = [sent.strip().split(\" \") for sent in english_train]\n",
        "fr_train = [sent.strip().split(\" \") for sent in french_train]\n",
        "eng_test = [sent.strip().split(\" \") for sent in english_test]\n",
        "fr_test = [sent.strip().split(\" \") for sent in french_test] \n",
        "eng_dev = [sent.strip().split(\" \") for sent in english_val]\n",
        "fr_dev = [sent.strip().split(\" \") for sent in french_val]\n"
      ],
      "metadata": {
        "id": "NVPFQnhy7YD-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_idx2word = []\n",
        "fr_idx2word = []\n",
        "for en in [eng_train, eng_test]:\n",
        "    for sent in en:\n",
        "        for word in sent:\n",
        "            if word not in en_idx2word:\n",
        "                en_idx2word.append(word)\n",
        "for fr in [fr_train, fr_test]:\n",
        "    for sent in fr:\n",
        "        for word in sent:\n",
        "            if word not in fr_idx2word:\n",
        "                fr_idx2word.append(word)\n",
        "en_idx2word = ['<PAD>', '<SOS>','<EOS>'] + en_idx2word\n",
        "fr_idx2word = ['<PAD>', '<SOS>','<EOS>'] + fr_idx2word\n",
        "#print few words\n",
        "print(en_idx2word[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wAOyWJz7Z8T",
        "outputId": "df4c8117-cb9e-408d-a482-21803e5dd0f3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<PAD>', '<SOS>', '<EOS>', 'David', 'Gallo:', 'This', 'is', 'Bill', 'Lange.', \"I'm\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_word2idx = {word:idx for idx, word in enumerate(en_idx2word)}\n",
        "fr_word2idx = {word:idx for idx, word in enumerate(fr_idx2word)}"
      ],
      "metadata": {
        "id": "OBwt_C-v7bYq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def len_comparison(A_train,B_train):\n",
        "    A_lengths = sum([len(sent) for sent in A_train])/len(A_train)\n",
        "    B_lengths = sum([len(sent) for sent in B_train])/len(B_train)\n",
        "    biggest_val = max(A_lengths,B_lengths)\n",
        "    #round of biggest val to nearest 10\n",
        "    biggest_val = round(biggest_val, -1)\n",
        "    return biggest_val\n",
        "seq_length = len_comparison(eng_train,fr_train)\n",
        "seq_length = int(seq_length)\n",
        "print(seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F4yP5xh7ctx",
        "outputId": "b41442d9-b881-49b5-890d-95eb1179cc4d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 20\n",
        "def encode_and_pad(vocab, sent, max_length):\n",
        "    sos = [vocab[\"<SOS>\"]]\n",
        "    eos = [vocab[\"<EOS>\"]]\n",
        "    pad = [vocab[\"<PAD>\"]]\n",
        "\n",
        "    if len(sent) < max_length - 2: # -2 for SOS and EOS\n",
        "        n_pads = max_length - 2 - len(sent)\n",
        "        encoded = [vocab[w] for w in sent]\n",
        "        return sos + encoded + eos + pad * n_pads \n",
        "    else: # sent is longer than max_length; truncating\n",
        "        encoded = [vocab[w] for w in sent]\n",
        "        truncated = encoded[:max_length - 2]\n",
        "        return sos + truncated + eos\n",
        "en_train_encoded = [encode_and_pad(en_word2idx, sent, sequence_length) for sent in eng_train]\n",
        "fr_train_encoded = [encode_and_pad(fr_word2idx, sent, sequence_length) for sent in fr_train]\n",
        "en_test_encoded = [encode_and_pad(en_word2idx, sent, sequence_length) for sent in eng_test]\n",
        "fr_test_encoded = [encode_and_pad(fr_word2idx, sent, sequence_length) for sent in fr_test]"
      ],
      "metadata": {
        "id": "opGWRt5Z7eN9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "batch_size = 50\n"
      ],
      "metadata": {
        "id": "WXlbwOGH7foB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = np.array(en_train_encoded)\n",
        "train_y = np.array(fr_train_encoded)\n",
        "test_x = np.array(en_test_encoded)\n",
        "test_y = np.array(fr_test_encoded)\n",
        "\n",
        "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "# def view_train_test(data):\n",
        "#   for i, (x, y) in enumerate(data):\n",
        "#       if i > 5:\n",
        "#           break\n",
        "#       print(x.shape, y.shape)\n",
        "#       print(x[0])\n",
        "#       print(y[0])\n",
        "# view_train_test(train_dl)"
      ],
      "metadata": {
        "id": "ADS6iluZ7hP-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class EncoderRNN(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size):\n",
        "#         super(EncoderRNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0) #If specified, the entries at padding_idx do not contribute to the gradient\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True) #Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
        "#         #If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). \n",
        "#     def forward(self, input, hidden):\n",
        "#         embedded = self.embedding(input)\n",
        "#         output = embedded\n",
        "#         output, hidden = self.gru(output, hidden)\n",
        "#         return output, hidden\n",
        "#     def initHidden(self):\n",
        "#         return torch.zeros(1, batch_size, self.hidden_size)\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n",
        "        \n",
        "        # GRU layer. The input and output are both of the same size \n",
        "        #  since embedding size = hidden size in this example\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # The inputs are first transformed into embeddings\n",
        "        embedded = self.embedding(input)\n",
        "        output = embedded\n",
        "\n",
        "        # As in any RNN, the new input and the previous hidden states are fed\n",
        "        #  into the model at each time step \n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        # This method is used to create the innitial hidden states for the encoder\n",
        "        return torch.zeros(1, batch_size, self.hidden_size)"
      ],
      "metadata": {
        "id": "xT746T1c7ip5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class DecoderRNN(nn.Module):\n",
        "#     def __init__(self, hidden_size, output_size):\n",
        "#         super(DecoderRNN, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0) #If specified, the entries at padding_idx do not contribute to the gradient\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "#         self.out = nn.Linear(hidden_size, output_size)\n",
        "#         self.softmax = nn.LogSoftmax(dim=1)\n",
        "#     def forward(self, input, hidden):\n",
        "#         output, hidden = self.gru(F.relu(self.embedding(input)), hidden)\n",
        "#         output = self.softmax(self.out(output[0]))\n",
        "#         return output, hidden\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0)\n",
        "        \n",
        "        # The GRU layer\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "        # Fully-connected layer for scores\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # Applying Softmax to the scores\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # Feeding input through embedding layer\n",
        "        output = self.embedding(input)\n",
        "\n",
        "        # Applying an activation function (ReLu)\n",
        "        output = F.relu(output)\n",
        "\n",
        "        # Feeding input and previous hidden state\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        # Outputting scores from the final time-step\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        \n",
        "        return output, hidden\n",
        "\n"
      ],
      "metadata": {
        "id": "-Oo2woiM7kbB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "encoder = EncoderRNN(len(en_word2idx), hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, len(fr_word2idx)).to(device)\n",
        "print(encoder)\n",
        "print(decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbhpXFTv7lsA",
        "outputId": "dafa8c4a-4b6b-4739-8352-ae5655005ec7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderRNN(\n",
            "  (embedding): Embedding(44975, 128, padding_idx=0)\n",
            "  (gru): GRU(128, 128, batch_first=True)\n",
            ")\n",
            "DecoderRNN(\n",
            "  (embedding): Embedding(55486, 128, padding_idx=0)\n",
            "  (gru): GRU(128, 128)\n",
            "  (out): Linear(in_features=128, out_features=55486, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create seq2seq\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    def forward(self, input, target, teacher_forcing_ratio=0.5):\n",
        "        input_length = input.size(0)\n",
        "        target_length = target.size(0)\n",
        "        encoder_outputs = torch.zeros(input_length, encoder.hidden_size, device=device)\n",
        "        encoder_outputs = encoder_outputs.to(device)\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_hidden = encoder_hidden.to(device)\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        decoder_input = torch.tensor([[fr_word2idx['<SOS>']]], device=device)\n",
        "        decoder_input = decoder_input.to(device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = torch.zeros(target_length, decoder.hidden_size, device=device)\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            decoder_outputs[di] = decoder_output[0, 0]\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        return decoder_outputs\n",
        "seq2seq = Seq2Seq(encoder, decoder).to(device)\n",
        "#print seq2seq architecture\n",
        "print(seq2seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmf1nsxB7nKm",
        "outputId": "eed1aa32-dd9e-4ba9-f043-c470b9e0bfbc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seq2Seq(\n",
            "  (encoder): EncoderRNN(\n",
            "    (embedding): Embedding(44975, 128, padding_idx=0)\n",
            "    (gru): GRU(128, 128, batch_first=True)\n",
            "  )\n",
            "  (decoder): DecoderRNN(\n",
            "    (embedding): Embedding(55486, 128, padding_idx=0)\n",
            "    (gru): GRU(128, 128)\n",
            "    (out): Linear(in_features=128, out_features=55486, bias=True)\n",
            "    (softmax): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.002)\n",
        "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.002)"
      ],
      "metadata": {
        "id": "8QSyyTR97oMY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "input_length = target_length = 20\n",
        "SOS = en_word2idx['<SOS>']\n",
        "EOS = en_word2idx['<EOS>']\n",
        "PAD = en_word2idx['<PAD>']\n",
        "epochs = 30\n"
      ],
      "metadata": {
        "id": "2nuF-28r7pSC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 7\n",
        "for epoch in range(epochs):\n",
        "    for idx, batch in enumerate(train_dl):\n",
        "\n",
        "        # Creating initial hidden states for the encoder\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        # Sending to device \n",
        "        encoder_hidden = encoder_hidden.to(device)\n",
        "\n",
        "        # Assigning the input and sending to device\n",
        "        input_tensor = batch[0].to(device)\n",
        "\n",
        "        # Assigning the output and sending to device\n",
        "        target_tensor = batch[1].to(device)\n",
        "        \n",
        "\n",
        "        # Clearing gradients\n",
        "        enc_optimizer.zero_grad()\n",
        "        dec_optimizer.zero_grad()\n",
        "\n",
        "        # Enabling gradient calculation\n",
        "        with torch.set_grad_enabled(True):\n",
        "            \n",
        "            # Feeding batch into encoder\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "\n",
        "            # This is a placeholder tensor for decoder outputs. We send it to device as well\n",
        "            dec_result = torch.zeros(target_length, batch_size, len(fr_idx2word)).to(device)\n",
        "\n",
        "            # Creating a batch of SOS tokens which will all be fed to the decoder\n",
        "            decoder_input = target_tensor[:, 0].unsqueeze(dim=0).to(device)\n",
        "\n",
        "            # Creating initial hidden states of the decoder by copying encoder hidden states\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            # For each time-step in decoding:\n",
        "            for i in range(1, target_length):\n",
        "                \n",
        "                # Feed input and previous hidden states \n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                \n",
        "                # Finding the best scoring word\n",
        "                best = decoder_output.argmax(1)\n",
        "\n",
        "                # Assigning next input as current best word\n",
        "                decoder_input = best.unsqueeze(dim=0) \n",
        "\n",
        "                # Creating an entry in the placeholder output tensor\n",
        "                dec_result[i] = decoder_output\n",
        "\n",
        "\n",
        "            # Creating scores and targets for loss calculation\n",
        "            scores = dec_result.transpose(1, 0)[1:].reshape(-1, dec_result.shape[2])\n",
        "            targets = target_tensor[1:].reshape(-1)\n",
        "\n",
        "            # Calculating loss\n",
        "            loss = criterion(scores, targets)\n",
        "            \n",
        "            # Performing backprop and clipping excess gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "\n",
        "            enc_optimizer.step()\n",
        "            dec_optimizer.step()\n",
        "\n",
        "            # Keeping track of loss\n",
        "            losses.append(loss.item())\n",
        "            if idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}/{epochs}, Batch: {idx}/{len(train_dl)}, Loss: {sum(losses)/len(losses)}')\n",
        "            # if idx % 100 == 0:\n",
        "            #     print(idx, sum(losses)/len(losses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBT9-xbl7qXS",
        "outputId": "73981ba7-b576-4537-8851-543dc98b3fc9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/7, Batch: 0/600, Loss: 10.920042991638184\n",
            "Epoch: 0/7, Batch: 100/600, Loss: 6.632684537679842\n",
            "Epoch: 0/7, Batch: 200/600, Loss: 6.175141825604794\n",
            "Epoch: 0/7, Batch: 300/600, Loss: 5.987822188887486\n",
            "Epoch: 0/7, Batch: 400/600, Loss: 5.877352942849632\n",
            "Epoch: 0/7, Batch: 500/600, Loss: 5.802076284518975\n",
            "Epoch: 1/7, Batch: 0/600, Loss: 5.742351811261423\n",
            "Epoch: 1/7, Batch: 100/600, Loss: 5.660721302032471\n",
            "Epoch: 1/7, Batch: 200/600, Loss: 5.596802135829473\n",
            "Epoch: 1/7, Batch: 300/600, Loss: 5.550576944065411\n",
            "Epoch: 1/7, Batch: 400/600, Loss: 5.512549780465506\n",
            "Epoch: 1/7, Batch: 500/600, Loss: 5.477068690578035\n",
            "Epoch: 2/7, Batch: 0/600, Loss: 5.450500108717284\n",
            "Epoch: 2/7, Batch: 100/600, Loss: 5.408234708772816\n",
            "Epoch: 2/7, Batch: 200/600, Loss: 5.37424393026936\n",
            "Epoch: 2/7, Batch: 300/600, Loss: 5.342757812108618\n",
            "Epoch: 2/7, Batch: 400/600, Loss: 5.316637477898583\n",
            "Epoch: 2/7, Batch: 500/600, Loss: 5.295187398729992\n",
            "Epoch: 3/7, Batch: 0/600, Loss: 5.2750931649258375\n",
            "Epoch: 3/7, Batch: 100/600, Loss: 5.245227768319585\n",
            "Epoch: 3/7, Batch: 200/600, Loss: 5.218748657897613\n",
            "Epoch: 3/7, Batch: 300/600, Loss: 5.193772295098938\n",
            "Epoch: 3/7, Batch: 400/600, Loss: 5.172694918027199\n",
            "Epoch: 3/7, Batch: 500/600, Loss: 5.15285106733124\n",
            "Epoch: 4/7, Batch: 0/600, Loss: 5.136213459009332\n",
            "Epoch: 4/7, Batch: 100/600, Loss: 5.1096359601453605\n",
            "Epoch: 4/7, Batch: 200/600, Loss: 5.085387924642391\n",
            "Epoch: 4/7, Batch: 300/600, Loss: 5.064394838057019\n",
            "Epoch: 4/7, Batch: 400/600, Loss: 5.046820302215571\n",
            "Epoch: 4/7, Batch: 500/600, Loss: 5.029683660943111\n",
            "Epoch: 5/7, Batch: 0/600, Loss: 5.013388154428031\n",
            "Epoch: 5/7, Batch: 100/600, Loss: 4.989766187338781\n",
            "Epoch: 5/7, Batch: 200/600, Loss: 4.968918601411166\n",
            "Epoch: 5/7, Batch: 300/600, Loss: 4.950553113639228\n",
            "Epoch: 5/7, Batch: 400/600, Loss: 4.933286703884233\n",
            "Epoch: 5/7, Batch: 500/600, Loss: 4.91660886790132\n",
            "Epoch: 6/7, Batch: 0/600, Loss: 4.902493491897117\n",
            "Epoch: 6/7, Batch: 100/600, Loss: 4.880065430309025\n",
            "Epoch: 6/7, Batch: 200/600, Loss: 4.860352302908552\n",
            "Epoch: 6/7, Batch: 300/600, Loss: 4.843763913108397\n",
            "Epoch: 6/7, Batch: 400/600, Loss: 4.828549458783319\n",
            "Epoch: 6/7, Batch: 500/600, Loss: 4.8138435000298925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "plt.savefig('m2.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OnKCiCtj7tSk",
        "outputId": "b261cf09-22bc-4535-8ae3-7e19af454ad8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#translate an input sentence\n",
        "def translate(sentence,en_word2idx,fr_idx2word,sequence_length,target_length,hidden_size,enc_optimizer,dec_optimizer,encoder,decoder):\n",
        "    SOS = en_word2idx['<SOS>']\n",
        "    EOS = en_word2idx['<EOS>']\n",
        "    test_sentence = torch.tensor(encode_and_pad(en_word2idx, sentence.split(), sequence_length)).unsqueeze(dim=0)\n",
        "    encoder_hidden = torch.zeros(1, 1, hidden_size)\n",
        "    encoder_hidden = encoder_hidden.to(device)\n",
        "    input_tensor = test_sentence.to(device)\n",
        "    enc_optimizer.zero_grad()\n",
        "    dec_optimizer.zero_grad()\n",
        "    result = []\n",
        "    encoder_outputs = torch.zeros(sequence_length, encoder.hidden_size, device=device)\n",
        "    with torch.set_grad_enabled(False):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "        dec_result = torch.zeros(target_length, 1, len(fr_idx2word)).to(device)\n",
        "        decoder_input = torch.tensor([SOS]).unsqueeze(dim=0).to(device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        for di in range(1, target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            best = decoder_output.argmax(1)\n",
        "            result.append(fr_idx2word[best.to('cpu').item()])\n",
        "            if best.item() == EOS:\n",
        "                break\n",
        "\n",
        "            decoder_input = best.unsqueeze(dim=0) \n",
        "            dec_result[di] = decoder_output\n",
        "\n",
        "        scores = dec_result.reshape(-1, dec_result.shape[2])\n",
        "        targets = target_tensor.reshape(-1)\n",
        "    return result\n",
        "# sentence = 'But see all those different working things?'\n",
        "# predicted = translate(sentence,en_word2idx,fr_idx2word,sequence_length,target_length,hidden_size,enc_optimizer,dec_optimizer,encoder,decoder)\n",
        "# predicted = \" \".join(predicted)\n",
        "# predicted\n",
        "\n"
      ],
      "metadata": {
        "id": "qQgmcMYX72L2"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list = []\n",
        "for train_sent in english_test:\n",
        "  predicted = translate(train_sent,en_word2idx,fr_idx2word,sequence_length,target_length,hidden_size,enc_optimizer,dec_optimizer,encoder,decoder)\n",
        "  predicted = \" \".join(predicted)\n",
        "  pred_list.append(predicted)\n",
        "print(pred_list[:2])\n"
      ],
      "metadata": {
        "id": "EKTGDy9y8doC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceae404c-fb3f-47cb-df62-e8ac365814d9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"J'ai j'ai j'ai j'ai j'ai j'ai de j'ai de j'ai de ma ma <EOS>\", 'Je suis une dans dans dans dans dans de <EOS>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('your_file1.txt', 'w') as f:\n",
        "    for item in pred_list:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "6YFl5jo9FGDM"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "def bleu_score(target, pred):\n",
        "    pred = pred.strip().split(\" \")\n",
        "    target = [target.strip().split(\" \")]\n",
        "    return sentence_bleu(target, pred)\n",
        "total_p = []\n",
        "total_t = []\n",
        "scores = []\n",
        "for i in range(len(english_test)):\n",
        "  scores.append(bleu_score(french_test[i],pred_list[i]))\n",
        "  total_p.append(pred_list[i].strip().split(\" \"))\n",
        "  total_t.append([french_test[i].strip().split(\" \")])\n",
        "val = corpus_bleu(total_t, total_p)\n",
        "val"
      ],
      "metadata": {
        "id": "_HSYr-MN8ICg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74934c0-8610-4bbe-dd5f-8ab62257ba9b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0068930998863544115"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"2020114017_MT1_test.txt\",\"w\")#write mode\n",
        "file1.write(str(val) + \"\\n\")\n",
        "for i in range(len(pred_list)):\n",
        "    file1.write(pred_list[i]+'\\t'+str(scores[i])+'\\n')\n",
        "file1.close()"
      ],
      "metadata": {
        "id": "TGv7W9nd_GBv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8-v-2L-UFXAq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}